{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<think>\n",
      "\n",
      "</think>\n",
      "\n",
      "The movie \"It\" (2014) isDirected by360°, starred in its original form with Vlad interchange with a mix of different countries. The original theatrical version is called *Famusz* and its official title is *It: Maternal Labor and the Rise of Modern Family Dynamics*. \n",
      "\n",
      "A film adaptation has been released as *Family* (2018), which features some original cast members, but it's also available on other platforms like Amazon Prime.\n"
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "client = OpenAI(\n",
    "    base_url = 'http://localhost:11434/v1',\n",
    "    api_key='ollama', # required, but unused\n",
    ")\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "  model=\"deepseek-r1:1.5b\",\n",
    "  messages=[\n",
    "    {\"role\": \"system\", \"content\": \" You are a helpful assistant.\"},\n",
    "    {\"role\": \"user\", \"content\": \"Who won the world series in 2020?\"},\n",
    "    {\"role\": \"assistant\", \"content\": \"The LA Dodgers won in 2020.\"},\n",
    "    {\"role\": \"user\", \"content\": \"Where was it played?\"}\n",
    "  ]\n",
    ")\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.chat_models import ChatOllama\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain.chains import LLMChain\n",
    "\n",
    "# Step 1: Initialize the Ollama model\n",
    "chat_model = ChatOllama(model=\"llama3.2:latest\")  # Replace with your Ollama model\n",
    "\n",
    "# Step 2: Define a prompt for query expansion\n",
    "expansion_prompt = ChatPromptTemplate.from_template(\n",
    "        \"\"\"\n",
    "        Return please multiple paraphrased variations, only the questions.\n",
    "        \n",
    "        Args:\n",
    "            {question} (str): The original question to expand\n",
    "            \n",
    "        \"\"\"\n",
    ")\n",
    "\n",
    "\"\"\"Returns:\n",
    "         List[str]: List of paraphrased variations of the question\n",
    " \"\"\"\n",
    "# Step 3: Create a chain for query expansion\n",
    "expansion_chain = LLMChain(\n",
    "    llm=chat_model,\n",
    "    prompt=expansion_prompt,\n",
    ")\n",
    "\n",
    "# Step 4: Define a function to refine the expanded query\n",
    "def refine_expansion(output: str) -> str:\n",
    "    # Remove unnecessary text and clean up the output\n",
    "    expanded_terms = output.strip().split(\"\\n\")\n",
    "    expanded_terms =[term.strip() for term in expanded_terms if term.strip()]\n",
    "    #eval(output.strip().split(\"# Output:\")[1])\n",
    "   # [term.strip() for term in expanded_terms if term.strip()]\n",
    "    return expanded_terms\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 5: Create the full pipeline\n",
    "def query_expansion_pipeline(query: str) -> str:\n",
    "    # Generate expanded terms\n",
    "    expansion_output = expansion_chain.run(query)\n",
    "    # Refine the output\n",
    "    refined_expansion = refine_expansion(expansion_output)\n",
    "    return  refined_expansion\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Query: what is rag\n",
      "Expanded Query: ['Here are some paraphrased variations of the input string \"what is rag\":', '1. What does rag mean?', '2. How do you pronounce rag?', '3. What is the definition of rag?', '4. Is there a specific context for the term rag?', '5. Can you explain what rag refers to?', '6. Does the term rag have any cultural or historical significance?', '7. What does the word rag imply or suggest?', '8. Is rag a common term in everyday language?', '9. How is rag related to other similar terms or concepts?', '10. Can you provide more information about the meaning of rag?']\n"
     ]
    }
   ],
   "source": [
    "# Step 6: Test the pipeline\n",
    "query = \"what is rag\"\n",
    "expanded_query = query_expansion_pipeline(query)\n",
    "reponse=expanded_query\n",
    "print(f\"Original Query: {query}\")\n",
    "print(f\"Expanded Query: {reponse}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Here are some paraphrased variations of the input string \"what is rag\":'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(expanded_query)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "variations = [result for result in expanded_query]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Dict' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[30], line 5\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# Set up cache\u001b[39;00m\n\u001b[0;32m      4\u001b[0m set_llm_cache(InMemoryCache())\n\u001b[1;32m----> 5\u001b[0m query_cache: \u001b[43mDict\u001b[49m[\u001b[38;5;28mstr\u001b[39m, Tuple[\u001b[38;5;28mstr\u001b[39m, \u001b[38;5;28mfloat\u001b[39m]] \u001b[38;5;241m=\u001b[39m {}\n",
      "\u001b[1;31mNameError\u001b[0m: name 'Dict' is not defined"
     ]
    }
   ],
   "source": [
    "from langchain_core.globals import set_llm_cache\n",
    "from langchain_core.caches import InMemoryCache\n",
    "# Set up cache\n",
    "set_llm_cache(InMemoryCache())\n",
    "query_cache: Dict[str, Tuple[str, float]] = {}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<think>\\nAlright, so I need to expand the term \"rag\" for better search results. Let me think about all possible meanings and related terms that might be associated with \"rag.\" \\n\\nFirst off, \"rag\" can refer to animal hair. That\\'s straightforward, but maybe adding something about its texture could help. Words like curly, fine, silky come to mind because they describe the appearance of animal hair.\\n\\nI also remember that in art or painting, \"rag\" might be used metaphorically to describe a rough, unpolished surface. So expanding on that with terms like weathered, worn away sounds useful.\\n\\nIn gaming contexts, particularly card games, \"rag\" can mean a specific card. That\\'s another relevant term, so including it makes sense. It\\'s probably used when discussing playing cards or strategy games.\\n\\nI should also consider the physical aspects—like how tightly wound or thick it is could be important terms for someone searching for information on ragging. So adding terms like tight wound and thick might add more depth to the query.\\n\\nMoreover, in historical contexts, especially in music or literature, \"rag\" can refer to a long, flowing melody. Including that term would give the search wider scope if it\\'s used there.\\n\\nThinking about materials, since hair is often made of various substances, expanding on that with things like silk, cotton, wool, and linen could be helpful for specific searches related to animal fur or natural fibers.\\n\\nIn culinary contexts, especially in certain cuisines, \"rag\" might refer to a particular sauce. That\\'s another useful term if it\\'s being used in that context.\\n\\nLastly, when discussing clothing, particularly tight-fitting attire, \"rag\" can denote the style of clothing with such characteristics. This could be relevant for someone looking into fashion or specific types of wear.\\n\\nPutting all these together, I think expanding \" rag\" with terms like animal hair, texture, weathered, worn away, card, playing cards, long flowing melody, material, and clothing attire would cover a broad range of contexts where the term might appear. It should help in providing more precise search results across various topics related to hair or related substances.\\n</think>\\n\\nThe expanded list of terms related to \"rag\" includes:\\n\\n- Animal hair\\n- Texture (curly, fine, silky)\\n- Weathered, worn away\\n- Card\\n- Playing cards\\n- Long flowing melody\\n- Material (silk, cotton, wool, linen)\\n- Dressage\\n- Running shoe'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "expanded_query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Query: machine learning\n",
      "Expanded Query (Filtered): like clustering algorithms.\n",
      "\n",
      "Deep learning is another area within machine learning. It uses neural networks with many layers. That sounds a bit more complex than just regular learning. So maybe that should be on the list too.\n",
      "\n",
      "I also think about practical applications of ML. Classification comes to mind—like predicting whether something will happen or not, deep learning, that should cover the expanded terms without missing anything.\n",
      "</think>\n",
      "\n",
      "machine learning expanded terms or phrases:\n",
      "\n",
      "- Supervised Learning\n",
      "- Unsupervised Learning\n",
      "- Deep Learning\n",
      "- Classification\n",
      "- Clustering\n",
      "- Reinforcement Learning\n",
      "- Natural Language Processing\n",
      "- Ethical Considerations\n"
     ]
    }
   ],
   "source": [
    "def filter_terms(terms: list, context: str) -> list:\n",
    "    # Example: Filter terms based on relevance to the context\n",
    "    relevant_terms = [term for term in terms if context.lower() in term.lower()]\n",
    "    return relevant_terms\n",
    "def query_expansion_pipeline(query: str, context: str) -> str:\n",
    "    # Generate expanded terms\n",
    "    expansion_output = expansion_chain.run(query=query, context=context)\n",
    "    # Refine the output\n",
    "    expanded_terms = refine_expansion(expansion_output).split(\", \")\n",
    "    # Filter terms based on context\n",
    "    filtered_terms = filter_terms(expanded_terms, context)\n",
    "    return \", \".join(filtered_terms)\n",
    "\n",
    "# Test the advanced pipeline\n",
    "query = \"machine learning\"\n",
    "context = \"deep learning\"\n",
    "expanded_query = query_expansion_pipeline(query, context)\n",
    "print(f\"Original Query: {query}\")\n",
    "print(f\"Expanded Query (Filtered): {expanded_query}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "variations = [result.paraphrased_query for result in results]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ragenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
